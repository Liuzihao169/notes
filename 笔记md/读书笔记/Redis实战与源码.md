## Redis实战与源码

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210316081204206.png" alt="image-20210316081204206" style="zoom:30%;" />



###  **一、问题画像**

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210316081358165.png" alt="image-20210316081358165" style="zoom:40%;" />



### 二、Redis的数据类型 与 底层数据结构

![image-20210315193216923](https://gitee.com/liuzihao169/pic/raw/master/image/image-20210315193216923.png)

**为什么Redis快？**

- **内存数据库**、**高效的数据结构**

> 为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。 key - entry (任意集合的类型，都能这样保存)
>
> 因为这个哈希表保存了所有的键值对，所以，我也把它称为**全局哈希表**

 **全局hash表存在的问题?**

- **hash碰撞、rehash问题**

> rehash的过程：其实redis默认使用两张全局hash表
>
> 1. 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；
>
> 2. 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；
>
> 3. 释放哈希表 1 的空间。
>
> **但是是在处理过程中渐进式处理**：每次执行的时候，复制一次，避免了耗时的操作，保证了数据的正常访问。

### 三、为什么redis那么快

> 我们通常说，Redis 是单线程，主要是指 **Redis 的网络 IO和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程**。（但是确能达到每秒数10万的级别的访问能力）--------------**多路复用**
>
> 单线程的好处：没有多线程面临的共享资源的并发控制问题

####  扩展：IO模型

> 1、阻塞式IO模型 ：这是最传统的IO模型， sockt.read() 没有等到结果会一直等待
>
> 2、非阻塞式IO模型：不会阻塞但是，客户端会一直轮询，CPU还是被占用
>
> 3、IO复用模型：内核有一个线程会不断去轮询每个连接的状态，观察是否有事件发生
>
> 4、信号驱动IO模型：发起的sockt请求，会注册一个信号函数，然后用户线程会继续执行，准备就绪的时候会发一个信息
>
> 5、异步IO模型：用户线程发起一个read操作后可以立马去做另外的事情了，当内核返回一个成功的信号表示IO已经完成了，就可以直接去使用数据。**是真正的异步IO**
>
> 信号驱动IO模型 和 IO 复用模型 的第二个阶段 当内核进行数据拷贝的过程会让用户线程阻塞。

在 Redis 只运行单线程的情况下，**该机制允许内核中，同时存在多个监听套接字和已连接套接字**；内核会一直监听，连接请求 和数据请求，一旦有请求到达就会交给redis。 **从而实现一个Redis线程处理多个IO流的效果**

#### Reis 实际的IO模型

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210316210814199.png" alt="image-20210316210814199" style="zoom:50%;" />

1. 不断轮询，将发生的事件放到队列当中；redis基于事件处理队列 直接处理事件；所以如果队列中有处理慢点操作，就会影响其他

### 四、AOF日志

> 扩展：Mysql 的redo log 是重做日志 记录的是物理日志 也就修改之后的数据
>
> binlog 记录的 逻辑日志，就是sql语句

执行命令>写入内存 >写日志（优点：避免记录错命令、不会阻塞当前操作）

**写日志，宕机数据丢失问题**，配置回写磁盘的策略

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210316220948622.png" alt="image-20210316220948622" style="zoom:40%;" />

#### 4.1重写机制

重写机制具有多变一的功能，旧日志文件中的多条命令可以再重写后的新日志就变成一条新的日志了，具有多变一的功能。

#### **4.2 会不会阻塞主线程呢？**

不会，是利用子线程进行复制拷贝，总结来说就是 **一个拷贝，两处日志**

1、“一个拷贝”就是指，每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程,**将数据 写成操作**

2、拷贝过来后，新的有操作记录到 AOF 缓冲区，同时也会在AOF重做缓冲区，等拷贝后，新的操作也会被记录到重写AOF当中

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210317123827790.png" alt="image-20210317123827790" style="zoom:50%; float:left" />

####  4.3 是否存在阻塞风险？

1、子线程复制主线程的数据，是复制主线程 的内存表，也就是 （虚拟内存 与物理内存的映射关系），这个过程中可能会发生阻塞

2、重写复制的过程中，如果有一个bigkey进来，重新申请大块内存风险会变大，可能会产生阻塞风险。

#### 配置

> auto-aof-rewrite-percentage 100 
>
> auto-aof-rewrite-min-size 64mb
>
> // 文件体量超过64mb，且比上次重写后的体量增加了100%时自动触发重写

###  五、RDB日志

> 内存数据的某一个状态时刻记录

####  5.1 两个命令 save、bgsave 

1. Save: 会阻塞主线程
2. Bgsave: 专门个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是Redis RDB 文件生成的默认配置。

#### 5.2 如何执行

**写时复制技术**

1、bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件（复制的其实是基于原始数据的。虚拟- 物理 映射表，当主线程数据修改后，对应的物理地址也会修改，但是并不会影响子线程 bgsave 生成 RDB文件）

2、拍快照过程中产生的写操作会被复制一份，bgsave函数会将他读取到 RDB中

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210317205723291.png" alt="image-20210317205723291" style="zoom:40%;float: left" />

#### 5.3 频繁执行会带来额外的开销

1、磁盘的压力   2、fork创建这个过程会阻塞主线程

Redis 4.0 中提出了一个**混合使用 AOF 日志和内存快照**的功能，拍快照之后，到下次快照的中间，会有AOF增量变化的日志。

### 六、**数据同步：主从库如何实现数据一致？**

####  6.1 Redis的高可用代表什么呢？

答： 包含了两层含义：**数据尽量不丢失；服务尽量不中断**

| 问题           | 方法                        |
| -------------- | --------------------------- |
| 数据尽量不丢失 | AOF 和 RDB日志              |
| 服务尽量不中段 | 通过主、从库 读写分离的模式 |

#### 6.2 主从库之间完成第一次数据同步

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210321205550895.png" alt="image-20210321205550895" style="zoom:50%;float: left" />

> runID: 表示 主库的实例id
>
> offset：表示开始复制的位置
>
> Real buffer：是主库从库复制过程中，主库接收到的写请求

**主-从-从-从的级联分担模式，来分散主库的压力**

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210321210330802.png" alt="image-20210321210330802" style="zoom:50%; float: left" />

主从复制完成之后，主-从之间用**基于长连接的命令传播**，用于后续命令的传播，但是这个过程中存在网络风险点：

**网络阻塞、网络断开**

####  6.3 同步时如果网络断开如何处理？

> repl_backlog_buffer 是一个环形缓冲区，**主库会记录自己写到的位置，从库则会记录自己**
>
> **已经读到的位置**。
>
> repl_backlog_size ：这个配置参数。如果它配置得过小，在增量复制阶段，可能
>
> 会导致从库的复制进度赶不上主库，进而导致从库重新进行全量复制。

**答：**第一次全量同步后，网络断开恢复时采用的是 **增量同步**。那么如何确定增量同步的点 呢，就是通过

**repl_backlog_buffer**。从库首先会给主库发送 psync 命令，并把自己当前的slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset之间的差距。 **然后增量同步时，将这部分数据同步给从库就可以了**

#### 6.4 小结

Redis 主从同步：全量复制、基于长连接的命令传播，以及增量复制。

#### 6.5 为什么主从库的复制不使用AOF

> RDB是二进制文件，传输和存储都更有优势
>
> 恢复数据库时 RDB的效率要高于AOF

### 七、哨兵机制

主要就是解决主库挂了后，从库切换成主库面领的3个问题

> 哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。
>
> 1. 主库真的挂了吗？
>
> 2. 该选择哪个从库作为主库？
>
> 3. 怎么把新主库的相关信息通知给从库和客户端呢？

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210325212150293.png" alt="image-20210325212150293" style="zoom:30%; float:left" />

#### 7.1 主观下线和客观下线

哨兵集群通过投票判断 “客观下线”，通常超过2/n + 1个之后，会将主库标记为 **客观下线**; 而哨兵判断从库就可以直接标记为客观下线；

#### 7.2 如何选择新的主库

通过 筛选 + 打分

> **筛选**： 正常运行的从库，并且之前的网络状态要良好

> **打分**：从库优先级、从库复制进度以及从库 ID 号
>
> 从库优先级： slave-priority 配置

#### 7.2 问题： 在主从切换的过程中，是否还能接受客户端的请求？

主从集群一般是采用读写分离模式，当主库故障后，客户端仍然可以把读请求发送给从库，让从库服务。但是，对于写请求操作，客户端就无法执行了。

### 八、哨兵挂了，主从库还能切换吗？

#### 8.1 哨兵是如何组合成集群的

> _sentinel__:hello 不同的哨兵就是通过他来发现，并且相互通信的
>
> 哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制。通过一个共同订阅消息的频道，就可以共享不同哨兵的 基本信息。ip + 端口

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210325230228077.png" alt="image-20210325230228077" style="zoom:50%;float:left" />



#### 8.2  哨兵是如何知道从库的信息，并通知

> 是通过 哨兵像主库 发送info命令，他会返回所有slave从库节点的列表

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210325230815064.png" alt="image-20210325230815064" style="zoom:50%;float:left" />

#### 8.3 确定由哪个哨兵来进行实际的主从切换

客观下线的仲裁过程：

> 1.任何实例只要自己判断主库下线后，就会给其他哨兵发送 is-master-downby-addr。哨兵通过 Y/N 表示赞成或反对；
>
> 2.当自己的票获得数量 超过。quorum 设置的值 (就可以设置为客观下线了)
>
> 3.表明自己想执行主从切换，并且让哨兵为他进行投票，这个投票的过程称为leader选举
>
> 成为leader的条件：** 当拿到半数投票后，就可以充当leader了**
>
> **第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值**

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210326084201510.png" alt="image-20210326084201510" style="zoom:50%; float:left" />

#### 8.4 小结

为了实现主库切换，我们引入了哨兵；为了减少单个哨兵不可用或者误判，引入哨兵集群。

所有哨兵判断客观下线的配置值需要是一直的，否则可能会出现无法达成共识，然后误判主库下线

#### 8.5 问题

如果只有5个哨兵集群，如果3个挂了，剩下3个能否实现主从切换。quorum 值设为 2

> 答：不可以，因为 2个投票可以判断主管下线；但是 要大于半数才可以完成leader的选举 
>
> 哨兵对主从库进行的在线状态检查等操作，是属于一种时间事件，用一个定时器来完成，一般来说每100ms执行一次这些事件。每个哨兵的定时器执行周期都会加上一个小小的随机时间偏移，目的是让每个哨兵执行上述操作的时间能稍微错开些，也是为了避免它们都同时判定主库下线，同时选举Leader。

### 九、切片数据集，是加实例 还是加内存

1.数据量太大数

据量越大，fork 操作造成的主线程阻塞的时间越长。所以，在使用 RDB 对 25GB 的数据进行持久化时，数据量较大，后台运行的子进程在 fork 创建时阻塞了主线程，于是就导致Redis 响应变慢了。

#### 9.1 如何存储更多的数据

纵向扩展：升级单个redis实例的资源配置；**特点：实施简单，但是主线程fork子线程的时候可能会阻塞；受到硬件的制约**

横向扩展: 横向增加当前 Redis 实例的个数;**性能提升，但是数据如何分布，客户端如何访问**

#### 9.2 如何实现数据分片

> 采用 Redis Cluster 方案采用哈希槽Hash Slot，一个切片集群中有16384个哈希槽，这些槽类似与数据分区。会有一个映射关系
>
> 采用CRC16 算法对Key处理 然后 摩 16384 得到槽点位置

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210326212243505.png" alt="image-20210326212243505" style="zoom:40%;float:left" />

**在手动分配哈希槽时，需要把 16384 个槽都分配完，否则Redis 集群无法正常工作**。

#### 9.3 客户端如何知道实例槽的信息

> 客户端会缓存，实例的槽位信息，（Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信
>
> 息的扩散），所以访问任何实例的时候能够拿到所有实例的节点信息

#### 9.3 实例槽位发生变化时，如何处理

> 为什么会变化？
>
> 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽；
>
> 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。

Redis Cluster提供了一种 **重定向的方案**

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210326213428218.png" alt="image-20210326213428218" style="zoom:50%; float:left" />

#### 9.4 槽位正在迁移时

如果正在迁移，那么会返回  ASK命令 第一表明Solt数据还在迁移中；第二把最新实例的地址返回给客户端，可以通过ASKING 命令，

然后再发送操作命令。

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210326224139794.png" alt="image-20210326224139794" style="zoom:50%;float:left" />

### 1 - 9 问题合集

#### **1.Redis 什么时候做 rehash？**

> 1、装载因子≥1，同时，哈希表被允许进行 rehash；装载因子≥5。

#### 2.  **采用渐进式 hash 时，如果实例暂时没有收到新请求，是不是就不做 rehash 了？**

> Redis会定时执行一次rehash操作，并且时间不会超过1ms

#### 3. **主线程、子进程和后台线程的联系与区别**

进程一般是指资源分配单元，例如一个进程拥有自己的堆、栈、虚存空间（页表）、文件描述符等；而线程一般是指 CPU 进行调度和执行的实体。 **reids线程 一般指redis的这个进程**

#### 4. 写时复制的底层实现机制？

主线程 fork 出 bgsave 子进程后，bgsave 子进程实际是复制了主线程的页表。然后根据复制的页表生成 RDB文件，此时主线程的写操作并不影响生成RDB文件，而是将这个过程中的 写操作复制一份，然后执行到RDB文件当中。（子进程或者父进程对内存页进行修改时才进行复制）

####  5. replication buffer **和** **repl_backlog_buffer** **的区别**

 replication buffer 是主从库在进行全量复制时，主库上用于和从库连接的客户端的 buffer，而 repl_backlog_buffer 是为了支持从库增量复制，主库上用于持续保存写操作的一块专用 buffer。

### 十一、为什么String类型不好用

#### 11.1 为什么String类型的内存开销大？

> String 除了记录数据之外，还需要记录额外的一些信息 元数据信息 （如数据长度、空间使用等信息）

#### 11.2 String类型如何保存数据？

> 当你保存的是64位有符号的整数时，String类型会把它保存成一个8个字节的 Long类型整数，这种编码方式叫int类型编码

> 当你保持的数据中包含字符时，就会使用 **简单动态字符来保存**

**(简单动态字符)SDS 结构体**

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210327194355952.png" alt="image-20210327194355952" style="zoom:25%;float:left" />

> **buf**：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\0”，这就会额外占用 1 个字节的开销。
>
> **len**：占 4 个字节，表示 buf 的已用长度。
>
> **alloc**：也占个 4 字节，表示 buf 的实际分配长度，一般大于 len。

#### 11.3 Reais Object

> 因为 Redis 的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据。
>
> 包含了8字节的元数据(用来区分不同的类型) 和 8字节的指针

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210327195425910.png" alt="image-20210327195425910" style="zoom:33%; float:left" />

**不同的大小，有不同的存储格式**

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210327200120370.png" alt="image-20210327200120370" style="zoom:50%;float:left" />

#### 11.4 10位 key - value 一共需要多少字节 

> 整型 int 类型的编码 可以用redisoobject 直接存储数据，16个字节一个ID。
>
> redis的全局hash表  dictEntry 的结构体，它由3个部分组成， key、value 以及下一个 dictEntry，三个指针共 24 字节

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210327201357429.png" alt="image-20210327201357429" style="zoom:50%; float:left" />

但是由于 Redis 使用的内存分配库 jemalloc 了，每次分配时会找一个 >= 它请求分配的 最小2的N次幂，所以24个字节实际也就是 申请了32个字节。所以 32B + 32B = 64B

#### 11.5 用什么数据结构可以节省内存

使用压缩表：

> 。表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量，以及列表中的 entry 个数。压缩列表尾还有一个 zlend，表示列表结束。

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210327203039271.png" alt="image-20210327203039271" style="zoom:50%;float:left" />

**prev_len**: 表示前一个 entry 的长度

**encoding**：表示编码方式，1 字节；

**len**：表示自身长度，4 字节；

**(key)content**：保存实际数据;

当你用 String 类型时，一个键值对就有一个 dictEntry，要用 32 字节空间。但采用集合类型时，一个 key 就对应一个集合的数据，能保存的数据多了很多，但也只用了一个 dictEntry，这样就节省了内存。

**总共消耗： 8 + 1 + 1 + 4 = 14个字节**

#### 11.6 如何用集合类型保存单值的k-v

> 前一部分作为 Hash 集合的 key，后一部分作为Hash 集合的 value，这样一来，我们就可以把单值数据保存到 Hash 集合中了。
>
> 例如。100001 1234 
>
> 就可以 使用hashset进行存储：1000  01(key) - 1234(value)

**Hash 类型的底层结构是 hash表 和 压缩表，什么时候相互转换呢？**

> 设置了两个阀值 一但在阀值之外就会转换成 hash 表。
>
> hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。
>
> hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。

### 十二、有一亿个key 要统计，应该用哪种集合？

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210327224023450.png" alt="image-20210327224023450" style="zoom:40%; float:left" />

### 十三、数据类型GEO

> 在打车软件上叫车，这些都离不开基于位置信息服务（Location-Based Service，LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在LBS 服务的场景中，我们来看一下它的底层结构。

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210330191536037.png" alt="image-20210330191536037" style="zoom:50%;float:left" />

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210330191625776.png" alt="image-20210330191625776" style="zoom:50%;float:left" />

将 **经度 和 维度** 进行编码成一串数字，能作为 sortSet的权值



#### 13.1 RedisObject 

> RedisObject 包括元数和指针。元数据的功能是用来区分不同类型的数据类型；指针用来指向不同类型的值

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210330192237099.png" alt="image-20210330192237099" style="zoom:50%;float:left" />

> type：表示值的类型，涵盖了我们前面学习的五大基本类型；
>
> encoding：是值的编码方式，用来表示 Redis 中实现各个基本类型的底层数据结构，
>
> 例如 SDS、压缩列表、哈希表、跳表等；
>
> lru：记录了这个对象最后一次被访问的时间，用于淘汰过期的键值对；
>
> refcount：记录了对象的引用计数；
>
>  *ptr：是指向数据的指针

### 十四、如何在redis中保存时间序列数据

#### 14.1 基于Hash 和 sorted set 保存时间序列数据

> Hash 保存 k-v数据
>
> Sorted set 用来排序

利用**MULTI 和 EXEC 命令** 保证 redis 事务执行

#### 14.2 **基于** **RedisTimeSeries** **模块保存时间序列数据**

### 十五、消息队列的考验：Redis有哪些考验

#### 15.1 消息队列需要解决的3个问题：

**1.消息保序**

> 使用 LPUSH 命令 和  RPOP 命令 保证写入后读取消息的顺序 **消费者一直使用 while(1)监听处理消息的时候 会一直消耗CPU**
>
> 改进：提供使用  BRPOP 命令，再没有拿到数据时，会发生阻塞，不会消耗cup

**2.重复消息处理**

> 生产者定义一个 幂等id, 消费者自行控制幂等处理

**3.消息可靠性保证**

> 防止消费者，处理失败，消息丢失，可以使用BRPOPLPUSH 命令 ，这个命令可以将消息存储在另外一个 备份list当中

**生产者很多消息堆积；消费者及时处理不了，如何构建成一个消费组？**

#### 15.2 基于Stream的消息队列解决方案

> Streams 是 Redis 专门为消息队列设计的数据类型，它提供了丰富的消息队列操作命令。
>
> XADD：插入消息，保证有序，可以自动生成全局唯一 ID；
>
> XREAD：用于读取消息，可以按 ID 读取数据；
>
> XREADGROUP：按消费组形式读取消息；
>
> XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取
>
> 但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。

### 十六、**异步机制：如何避免单线程模型的阻塞？**

#### 16.1 Redis实例有哪些阻塞点？

> **客户端**：网络 IO，键值对增删改查操作，数据库操作；
>
> **磁盘**：生成 RDB 快照，记录 AOF 日志，AOF 日志重写；
>
> **主从节点**：主库生成、传输 RDB 文件，从库接收 RDB 文件、清空数据库、加载 RDB
>
> 文件；
>
> **切片集群实例**：向其他实例传输哈希槽信息，数据迁移。

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210331220610271.png" alt="image-20210331220610271" style="zoom:50%;float:left" />

#### 16.2 具体的阻塞操作

##### 16.2.1 客户端交互

1.聚合查询和全量操作

2.bigkey 删除操作就是 Redis 的第二个阻塞点

3.清空数据库

##### 16.2.2 和磁盘交互的时点

4.AOF日志同步写（ AOF 日志时，会根据不同的写回策略对数据做落盘保存）

##### 16.2.2**主从节点交互时的阻塞点**

5.加载RDB文件，主从同步时，会FLUSHDB 命令清空当前数据库，然后开始读取RDB文件

#### 16.3 异步的子线程机制

Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。**操作被封装成异步任务**

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210331223653497.png" alt="image-20210331223653497" style="zoom:50%;float:left" />

**删除 和清空数据库都可以采用 异步线程进行**

### 17. 为什么CPU的结构也会影响Redis性能

#### 17.1 CPU 结构

一个 CPU 处理器中一般有多个运行核心，我们把一个运行核心称为一个物理核，每个物理核都可以运行应用程序。每个物理核都拥有私有的一级缓存（Level 1 cache，简称 L1cache），包括一级指令缓存和一级数据缓存，以及私有的二级缓存（Level 2 cache，简称 L2 cache）。

不同核之间会有共享内存 L3缓存；

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210401223002442.png" alt="image-20210401223002442" style="zoom:50%;float:left" />

#### 17.2 cpu多核对redis性能的影响

在一个 CPU 核上运行时，应用程序需要记录自身使用的软硬件资源信息（例如栈指针、CPU 核的寄存器值等），我们把这些信息称为**运行时信息**。

线程在不同cpu间的切换，这个时候就要切换上下文信息了；

####  **CPU** **的** **NUMA** **架构对** **Redis** **性能的影响**

Redis 实例和网络中断程序的数据交互：

网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间。

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210401225457109.png" alt="image-20210401225457109" style="zoom:50%;float:left" />

**如果网络中断处理程序和 Redis 实例各自所绑的 CPU 核不在同一个 CPU Socket 上，那么，Redis 实例读取网络数据时，就需要跨 CPU Socket 访问内存，这个过程会花费较多时间。**

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210401225840597.png" alt="image-20210401225840597" style="zoom:50%;" />

所以要进行核绑定，让他在一个核中处理，能够提高效率。

### 18、波动的响应延迟

##### 18.1 排查和解决慢的操作

> 影响的关键因素： **文件系统**、**操作系统**

1. 从慢查询命令开始排查，并且根据业务需求替换慢查询命令；

2. 排查过期 key 的时间设置，并根据实际使用需求，设置不同的过期时间。

### 19、波动的响应延迟二

#### 19.1 文件系统影响

**AOF重写**：当在进行AOF重写的时候，磁盘压力会很大，此时如果设置了aof刷盘策略是‘awalys’时，那么高磁盘io会影响fsync，子线程的f ync就会影响主线程，导致redis的性能变慢。

![image-20210402203626953](https://gitee.com/liuzihao169/pic/raw/master/image/image-20210402203626953.png)



#### 19.2  操作系统的 swap

> 内存 swap 是操作系统里将内存数据在内存和磁盘间来回换入和换出的机制，涉及到磁盘的读写，所以，一旦触发 swap，无论是被换入数据的进程，还是被换出数据的进程，其性能都会受到慢速磁盘读写的影响。

引发原因： 物理机的内存不足

解决方法：**增加机器的内存或者使用 Redis 集群**

#### 19.3 内存大页

> Linux 内核从 2.6.38 开始支持内存大页机制，该机制支持 2MB 大小的内存页分配，而常规的内存页分配是按 4KB 的粒度来执行的。

当在作快照的时候，执行写时复制时，这个过程由其他线程完成，如果此时有数据被修改，Redis 并不会直接修改内存中的数据，而是将这些数据拷贝一份，然后再进行修改。如果采用了内存大页，那么，即使客户端请求只修改 100B 的数据，Redis 也需要拷贝2MB 的大页。**但是如果只是4kb的时候,也就只需要拷贝4kb了**

### 20. 删除数据后 为什么内存的占有率还是很高

#### 20.1 什么是内存碎片

> 使用内存空间时不连续，会有存在未被利用的“小间隙” ，这部分小间隙，就是内存碎片

####  20.2 内存碎片是如何形成的

> 简单来说，内因是操作系统的内存分配机制，外因是 Redis 的负载特征。

##### 内因：内存分配器的分配策略

Redis 可以使用 libc、jemalloc、tcmalloc 多种内存分配器来分配内存，默认使用jemalloc。会分配一个大于等于2的n次方的数据；

例如：申请一个20字节的数据内存，就会分配一个 32的内存 那么多的那部分 就会形成内存碎片；

##### 外因：健值对大小不一样和删除操作

#### 20.3 如何判断有内存碎片

> Redis 是内存数据库，内存利用率的高低直接关系到它的性能，所以它提供了相关的命令，info 命令
>
> INFO memory 
>
> \# Memory 
>
> used_memory:1073741736 
>
> used_memory_human:1024.00M 
>
> used_memory_rss:1997159792 
>
> used_memory_rss_human:1.86G 
>
> …
>
> mem_fragmentation_ratio:1.86 

**mem_fragmentation_ratio（碎片率）  = （used_memory_rss）实际的 /  used_memory（申请的）**

**当碎片率 >= 1.5 的时候 就需要注意了**

#### 20.4 如何清理碎片

1、直接重启red is 这并不是一个好的方法，可能会丢失数据

2、redis 4.0 之后 支持自动清理 

```mysql
但是整理碎片，会对
config set activedefrag yes
```

因为 Redis 是单线程，在数据拷贝时，Redis 只能等着，这就导致 Redis 无法及时处理请求，性能就会降低。

**通过参数设置阀值**

> **active-defrag-ignore-bytes 100mb**：表示内存碎片的字节数达到 100MB 时，开始
>
> 清理；
>
> **active-defrag-threshold-lower 10**：表示内存碎片空间占操作系统分配给 Redis 的
>
> 总空间比例达到 10% 时，开始清理。
>
> **active-defrag-cycle-min 25**： 表示自动清理过程所用 CPU 时间的比例不低于
>
> 25%，保证清理能正常开展；
>
> **active-defrag-cycle-max 75**：表示自动清理过程所用 CPU 时间的比例不高于
>
> 75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致
>
> 响应延迟升高。

### 二十一、11-20课后问题解答

#### 21.1 **除了 String 类型和 Hash 类型，还有什么类型适合保存第 11 讲中所说的图片吗？**



> 除了 String 和 Hash，我们还可以使用 Sorted Set 类型进行保存。Sorted Set 的元素有 member 值和 score 值，可以像 Hash 那样，使用二级编码进行保存。具体做法是，把图片 ID 的前 7 位作为 Sorted Set 的 key，把图片 ID 的后 3 位作为 member 值，图片存储对象 ID 作为 score 值。



#### 21.2 如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理

> 使用stream类型的消费组，消费者1 和消费者2 要属于不同的消费组；



#### 21.3 在一台有两个 CPU Socket（每个 Socket 8 个物理核），改如何分配

有两个方案：

> 1. 在同一个 CPU Socket 上运行 8 个实例，并和 8 个 CPU 核绑定；
> 2.  在两个 CPU Socket 上各运行 4 个实例，并和相应 Socket 上的核绑定。

方案一：同一个 CPU Socket 上的进程，会共享 L3 缓存。如果把 8 个实例都部署在同一个Socket 上，它们会竞争 L3 缓存，这就会导致它们的 L3 缓存命中率降低，影响访问性能。

切片机群当中，不同实例间通过网络进行消息通信和数据迁移，并不会使用共享内存空间进行跨实例的数据访问

#### 21.4 在 Redis 中，还有哪些命令可以代替 KEYS 命令，实现对键值对的 key 的模糊查询呢？这些命令的复杂度会导致 Redis 变慢吗？

> Redis 提供的 SCAN 命令，以及针对集合类型数据提供的 SSCAN、HSCAN 等，可以根据执行时设定的数量参数，返回指定数量的数据，这就可以避免像 KEYS 命令一样同时返回所有匹配的数据，不会导致 Redis 变慢。以 HSCAN 为例，我们可以执行下面的命令，从 user 这个 Hash 集合中返回 key 前缀以 103 开头的 100 个键值对。

```java
 HSCAN user 0 match "103*" 100
```

#### 21.4 你遇到过redis变慢的情况吗？

> \1. 使用复杂度过高的命令或一次查询全量数据；
>
> \2. 操作 bigkey；
>
> \3. 大量 key 集中过期；
>
> \4. 内存达到 maxmemory；
>
> \5. 客户端使用短连接和 Redis 相连；
>
> 当 Redis 实例的数据量大时，无论是生成 RDB，还是 AOF 重写，都会导致 fork 耗时
>
> 严重；
>
> 6.
>
> \7. AOF 的写回策略为 always，导致每个操作都要同步刷回磁盘；
>
> Redis 实例运行机器的内存不足，导致 swap 发生，Redis 需要到 swap 分区读取数
>
> 据；
>
> 8.
>
> \9. 进程绑定 CPU 不合理；
>
> \10. Redis 实例运行机器上开启了透明内存大页机制；
>
> \11. 网卡压力过大。

#### 21.5  mem_fragmentation_ratio 的值小于1 说明发生了什么

> 表明操作系统分配给red is的内存，小于redis 所申请内存的大小，此时redis实例内存已经不够用了，发生了swap

#### 21.6 在和redis的实际交互中，应用程序的客户端要使用缓冲程序吗

> 1、可以控制客户端端发送数率，请求不会一下子全部打到客户端
>
> 2、进行主从切换时，需要一定的时间，可以先缓存客户端的请求

#### 21.7 如何查询慢日志

> redis的慢查询日志，记录了执行时间超过一定阀值的命令操作；
>
> **slowlog-log-slower-than**：慢查询日志对执行时间大于多少微秒的数据进行记录
>
> **slowlog-max-len**：慢查询日志最多能记录多少条记录，如果超出，则会被删除；因为慢查询太多的话，日志就会存储不下，

 latency monitor 可以监控慢查询，并进行设置；

#### 21.8 如何排查redis的 bigkey 

```java
./redis-cli --bigkeys
```

建议：在redis实例压力低的进行扫描检查，以面影响实例的正常运行；

### 二十三、旁路缓存：Redis是如何工作的？

**缓存的特征？，为什么需要缓存**

> 一个系统中的不同层之间的访问速度不一样，所以我们才需要缓存，这样就可以把一些需要频繁访问的数据放在缓存中，以加快它们的访问速度。

#### 23.1 常见使用缓存模式

> 应用读取数据时，需要先读取 Redis；
>
> 发生缓存缺失时，需要从数据库读取数据；
>
> 发生缓存缺失时，还需要更新缓存。

#### 23.2 缓存类型

**只读缓存**

> 只允许读，不允许修改，当需要更新时，是会更新数据库的信息，然后删除缓存red is的数据，当下次访问该数据时，就会触发，缓存失效，red i就重新从mysql当中读取最新消息，存储在red is当中

**读写缓存**

> 风险：一旦出现掉电或宕机，内存中的数据就会丢失。这也就是说，应用的最新数据可能会丢失，给应用业务带来风险。

**同步直写：** 写缓存的同时，也会将写请求发送到后端数据库进行处理

**异步写回：** 所有写请求都先在缓存中处理。等到这些增改的数据要被从缓存中淘汰出来时，缓存将它们写回后端数据库，但是仍然会有断电丢失的风险；

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210405215844303.png" alt="image-20210405215844303" style="zoom:50%;float:left" />

### 24.替换策略，缓存被写满了怎么办

> 使用 80%的访问，只需要20%的缓存就能够借据

#### 24.1 设置多大缓存合适

要结合**应用数据实际访问特征**和**成本开销**来综合考虑的；我建议把缓存容量设置为缓存的15% - 30%

#### 24.2 Redis缓存有哪些淘汰策略

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210406114152762.png" alt="image-20210406114152762" style="zoom:50%;float:left" />

> 1、当缓存到达 maxmemory ，默认情况下并不会淘汰数据，而是直接报错，拒绝服务
>
> 2、用 EXPIRE 命令对一批键值对设置了过期时间后，无论是这些键值对的过期时间是快到了，还是 Redis 的内存使用量达到了 maxmemory 阈值，Redis 都会进一步按照 volatile-ttl、volatile-random、volatile-lru、volatile-lfu 这四种策略的具体筛选规则进行淘汰。
>
> t t l:按过期时间排序，越早过期越早被删除；random:随机删除；l ru: 根据l ru算法；l fu:根据l fu算法
>
> 备选淘汰算法：allkeys-lru、allkeys-random、allkeys-lfu；在所有的ke y中用对应的策略进行淘汰

#### LRU算法

> Least Recently Used ：这是按照最近最少使用的原则来筛选数据，最不常用的数据会被筛选出来，而最近频繁使用的数据会留在缓存中。

#### 改进的LUR算法：

> Redis 默认会记录每个数据的最近一次访问的时间戳（由键值对数据结构RedisObject 中的 lru 字段记录）。然后，Redis 在决定淘汰的数据时，第一次会随机选出N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把lru 字段值最小的数据从缓存中淘汰出去。
>
> **这样就不需要维护一下大链表；也不用移动链表项**

### 二十五、缓存异常：然后解决缓存缓存和数据库不一致的问题

**什么是数据的一致性**

> 缓存中有数据，那么，缓存的数据值需要和数据库中的值相同；
>
> 缓存中本身没有数据，那么，数据库中的值必须是最新值。

一致性要求高的，要想保持数据的一致性，就要使用同步直写；如果是非关键属性，那么就可以使用异步回写策略

#### 25.1 如何解决数据不一致问题

1、重试机制

> 将需要的操作，存储在消息队列当中，如果删除失败可以做补偿处理

##### 先删除缓存、后更新数据

带来的问题，如果更新的数据还没持久化到数据库，那么下次查询时，会查数据库，并存到缓存当中，会导致查询到的是旧数据

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210406185841867.png" alt="image-20210406185841867" style="zoom:40%;float:left" />

解决方法：

> **在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间，再进行一次缓存删除操作。**
>
> 延迟双删：

```java
redis.delKey(X) 
db.update(X) 
Thread.sleep(N) 
redis.delKey(X)
```

**先更新数据，再删除缓存**

> 带来的问题，查询数据时，发现命中缓存，会返回之前旧的数据；但是这样的情况并不会多，当缓存被删除后，其他线程里面就会拿到新的数据

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210406191217954.png" alt="image-20210406191217954" style="zoom:50%;float:left" />

#### 小结

大多数情况下，red is当作只读缓存，并且优先使用 **先更新数据库，再删除缓存**

原因：先缓存，可会导致请求全部落到数据库，会增加数据库压力；如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。

### **二十六、如何解决缓存雪崩、击穿、穿透难题？**

#### 26.1 缓存雪崩

> 缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。

原因：1、大量key 同时失效，导致请求同时堆积到数据库 

**解决方法：**a.key的过期时间，使用随机数  b.服务降级：当访问非核心业务时，暂停从缓存中查询数据，而是直接返回信息，空值，或者错误信息；

原因：2、redis 发生宕机：一个redis 能够支持万级别的吞吐量，而单个数据库能够支持千级别的吞吐量，所以当redis 宕机时，数据无法承受这个压力。

解决方法：在业务系统中熔断或请求限流机制

> 熔断：是指在发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，我们暂停业务应用对缓存系统的接口访问
>
> 请求限流机制：可以限制进入系统的请求数量。

**搭建高可用redis 集群**

#### 26.2 缓存击穿

> 缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。

解决方法：针对热点数据，就不设置过期时间；

#### 26.3 缓存穿透

> 缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。此时，应用也无法从数据库中读取数据再写入缓存，来服务后续请求，这样一来，缓存也就成了“摆设”，此时 数据库 和 redis 都同时面临很大的压力。

原因：1、数据误删除，缓存和数据的业务数据都误删除；2、恶意攻击

**解决方法：**

a. 在缓存中可以人为的针对缓存穿透数据，设置一个 默认值

b.使用用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。

> 首先，使用 N 个哈希函数，分别计算这个数据的哈希值，得到 N 个哈希值。然后，我们把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置。最后，我们把对应位置的 bit 位设置为 1，这就完成了在布隆过滤器中标记数据的操作。

c.前段请求检测 ，在前端就过滤恶意的访问请求

#### 26.4 小结

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210406223622334.png" alt="image-20210406223622334" style="zoom:50%;float:left" />

**预设方案：**

> 针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；
>
> 针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间；
>
> 针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。

### 二十七、缓存被污染了怎么办

**缓存污染**

> 在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。

#### 27.1 如何解决缓存污染问题

**淘汰算法**

> LRU 最近最少使用：Redis 中的 LRU 策略，会在每个数据对应的 RedisObject 结构体中设置一个 lru 字段，用来记录数据的访问时间戳；因为看中的因子是访问最近，所以无法使用最少使用
>
> LFU 最少次数使用：根据使用次数进行淘汰，如果当使用次数相同时就淘汰最久未被使用的

**LRU算法的实现**

> red is使用redisobject保存数据，其中有个lru字段，用来保存访问的时间戳；
>
> redis 并没有维护一个全局的时间链表，而是每次淘汰的时候，选取随机的一批数据，根据lru字段进行筛选

**LFU算法的实现：**

> Lfu 实际上是把原来的24位的l ru字段进行了拆分：
>
> ldt 值：lru 字段的前 16bit，表示数据的访问时间戳；
>
> counter 值：lru 字段的后 8bit，表示数据的访问次数。

**问题:** 8位能够记录的值最大的值是255 ，但是red is中的访问随便都超过这个数值；

**在实现 LFU 策略时，Redis 并没有采用数据每被访问一次，就给对应的 counter 值加 1 的计数规则，而是采用了一个更优化的计数规则**。

> 每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。

这样我们就可以通过控制lfu_log_factor的大小，来控制count增加的速度；

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210409083035347.png" alt="image-20210409083035347" style="zoom:50%;float:left" />

**问题：有些数据在短时间内被大量访问后就不会再被访问了？**

> 使用衰减值控制；LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。

#### 小结

1.volatile-random 和 allkeys-random 是随机选择数据进行淘汰，无法把不再访问的数据筛选出来，可能会造成缓存污染

2.LRU 策略无法很快将污染数据筛选出来 ； LFU只考虑了计算数据的实效性

3.LFU 策略在 LRU 策略基础上进行了优化，在筛选数据时，首先会筛选并淘汰访问次数少的数据，然后针对访问次数相同的数据

###  二十八、**Pika:** 如何基于SSD实现大容量Redis？

#### **大内存** **Redis** **实例的潜在问题**

1、RDB文件生成受影响，在fork主线程的时候，会发生阻塞；RDB进行回复的时长也会增加

2、主从同步受到影响：主从节点进行同步到时候如果RDB文件很大，那么在传输给从节点的时候，加载就会需要很多时间、复制过程中还可能发生溢出，然后可能又会开始全量同步；如果主从切换后，其他从库也会和主库同步一次RDB文件

**Pika架构图**

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210410191729415.png" alt="image-20210410191729415" style="zoom:50%;float:left" />



#### 28.1 网络框架

> 网络框架主要负责底层网络请求的接收和发送。Pika 的网络框架是对操作系统底层的网络函数进行了封装。Pika 在进行网络通信时，可以直接调用网络框架封装好的函数。

#### 28.2 Pika 线程模块

> Pika 线程模块采用了多线程模型来具体处理客户端请求，包括一个请求分发线程（DispatchThread）、一组工作线程（WorkerThread）以及一个线程池（ThreadPool）。

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210410192356204.png" alt="image-20210410192356204" style="zoom:50%; float:left" />

在实际业务处理的时候，可以增加工作线程的数量，和线程池的数量来提高效率；

#### 28.3 Nemo 模块

> 它实现了 Pika 和 Redis 的数据类型兼容；当我们把Redis 服务迁移到 Pika 时，不用修改业务应用中操作 Redis 的代码，而且还可以继续应用运维 Redis 的经验，这使得 Pika 的学习成本就较低

#### 28.4 **Pika** **如何基于** **SSD** **保存更多数据？**

Pika 使用了业界广泛应用的持久化键值数据库**RocksDB,** 数据读写机制，

**写过程**

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210410193516733.png" alt="image-20210410193516733" style="zoom:50%;float:left" />

> 他的关键采用了两块内存，进行交替读写机制，然后持久化键值对，生成相应文件落地；



**读过程**

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210410193811702.png" alt="image-20210410193811702" style="zoom:50%;float:left" />

> 读的时候会先从内存中读取因为里面有新的数据，当没有读取到的时候，就从 键值对文件中进行读取

#### 28.5 pika如何解决生成快照 和 主从同步问题

**快照问题：**

> pika基于roksdb生成了键值对文件，就不需要通过，快照来回复了；全量同步时，也可以就直接拷贝文件

**同步问题：**

> Pika 使用了 binlog 机制实现增量命令同步，既节省了内存，还避免了缓冲区溢出的问题。pika的内存在接收数据之后，也会把数据写在bin lo g当中；当全量同步结束后，从库会从 binlog 中把尚未同步的命令读取过来，这样就可以和主库的数据保持一致。当进行增量同步时

#### 28.6 pi ka的优势与不足

优势：重启快；主从同步风险低（Pika 通过 binlog 机制实现写命令的增量同步，不再受内存缓冲区大小的限制，所）

劣势：数据在SSD上，访问性就要差一些；

### 二十九、无锁的原子操作：Redis如何应对并发访问？

保证并发访问的正确性 

> 加锁、原子操作
>
> 加锁：加锁操作会降低系统的并发访问性能；涉及分布式锁，需要处理

#### 29.1 redis的两种原子操作

> \1. 把多个操作在 Redis 中实现成一个操作，也就是单命令操作；
>
> \2. 把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本。

**单命令操作：**

```java
INCR  +1操作
DECR  -1操作
```

**lua脚本**

> red is会把lu a脚本作为一个整体进行执行，不会被打断，也就是要么执行，要不执行

### 三十、**基于多个** **Redis** **节点实现高可靠的分布式锁**

**分布式算法锁**

> Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户
>
> 端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布
>
> 式锁了，否则加锁失败。

**客户端只有满足下面两个条件，加锁成功**

- 客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁；
- 客户端获取锁的总耗时没有超过锁的有效时间。

#### 29.3 小结

分布式锁是由共享存储系统维护的变量，多个客户端可以向共享存储系统发送命令进行加锁或释放锁操作。Redis 作为一个共享存储系统，可以用来实现分布式锁。

1、原子操作 加锁、判断、设置 3个操作

2、锁设置过期时间，防止客户端拿到锁之后发生异常而无法释放

3、锁需要判断是 加锁者（解铃还须系铃人）



### 三十一、事务机制：redis能实现 ACID吗

> 事务在执行时，会提供专门的属性保证，包括原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability），也就是 ACID 属性。这些属性既包括了对事务执行结果的要求，也有对数据库在事务执行前后的数据状态变化的要求。

原子性：一个事务中的操作要么不执行，要么全执行

一致性：数据库中的数据在事务执行前后是一致的

隔离性: 要求数据库在执行一个事务时，其它操作无法存取到正在执行事务访问的数据。

持久性: 数据的修改要被持久化下来，当数据库重启后要能够恢复

#### 31.1 redis 如何实现事务？

开启事务：MULTI ；提交事务：EXEC   

开启事务后，就是将客户端的请求存储到一个命令队列当中,并不会立即执行；服务器端获得到exec命令后，才开始执行。

#### 31.2 red is原子性相关

> 命令入队时就报错，会放弃事务执行，保证原子性；
>
> 命令入队时没报错，实际执行时报错，不保证原子性；
>
> EXEC 命令执行时实例故障，如果开启了 AOF 日志，可以保证原子性。

#### 31.3 reids 一致性相关

> redis 能够保证数据的一致性

#### 31.4 red is 隔离性相关

分两个时刻，exec命令前后；

当exec命令执行前，针对某个键有并发操作时，与是否开启watch命令有关

当execa命令执行之后，有并发操作，不会有隔离性问题

**watch机制**

> WATCH 机制的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行，隔离性也得到了保证。

#### 31.5 隔离性

不管是使用RDB. 还是 AOF，事务的持久性还是不能得到保证。**RDB不会在事务的时候执行**

#### 31.6 小结

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210415231027495.png" alt="image-20210415231027495" style="zoom:50%;" />

### 三十二、 **Redis**主从同步与故障切换，有哪些坑？

#### 32.1 主从数据不一致

> 主从数据不一致，就是指客户端从从库中读取到的值和主库中的最新值并不一致。

为什么会出现这个情况呢，因为主从之间的**命令复制是异步的**，所以当主库传播给从库的命令可能被延迟；即使从库接收了命令，也可能会因为正在处理其它复杂度高的命令（例如集合操作命令）而阻塞。而在被滞后的这段时间，可能主库又执行了其他操作；

##### 解决方案

1、从硬件方面尽可能保持主从的网络连接

2、外部程序监控主从复制的进度：Redis 的 INFO replication 命令可以查看主库接收写命令的进度信息（master_repl_offset）和从库复制写命令的进度信息（slave_repl_offset），所以，我们就可以开发一个监控程序，先用 INFO replication 命令查到主、从库的进度，然后，我们用 master_repl_offset 减去 slave_repl_offset，这样就能得到从库和主库间的复制进度差值了。

**当差异较大的时候，就可让客户端不从该从库读取数据**

#### 32.2 读取过期数据

> 在使用redis主从集群时，有时会读取到过期数据

**Redis 同时使用了两种策略来删除过期的数据，分别是惰性删除策略和定期删除策略**。

> **惰性删除**：当一个数据过期时间到了后，并不会立即删除，而是等再有读请求来后，会检查数据，如果过期后，就执行删除；
>
> **定期删除：**，Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除，这样就可以及时释放一些内存。
>
> redis是3.2之前的版本，从库会查询到过期数据，3.2版本之后，会返回一个空数据，但是3.2版本之后，也可能会出现从库查到过期数据

**原因：** 与设置过期时间到命令有关

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210419162546312.png" alt="image-20210419162546312" style="zoom:50%;float:left" />

当主从同步有数据延迟的时候，如果使用expire命令，会导致，从库执行完该命令时，主库数据已经到达过期时间，但是查询从库，还能查到，所以建议使用 **expireat命令** 制定具体的过期时间

#### 32.3 不合理的配置导致服务挂掉

**protected-mode 配置项**

> Yes： 表示只能本地访问
>
> NO:  表示也能被其他服务访问
>
> 需要设置为 no;并且在 bind 中设置了 IP 地址的哨兵

**cluster-node-timeout 配置项**

> 如果执行主从切换的实例超过半数，而主从切换时间又过长的话，就可能有半数以上的实例心跳超时，从而可能导致整个集群挂掉。所以，**我建议你将 cluster-nodetimeout 调大些（例如 10 到 20 秒）**。

#### 小结

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210419164206505.png" alt="image-20210419164206505" style="zoom:50%;float:left" />

### 三十三、脑裂导致数据丢失

> 所谓脑裂就是，在主从集群中，有两个节点

#### 33.1 为什么会发生脑裂

> 当主从切换发生时，一定是有超过预设数量（quorum 配置项）的哨兵实例和主库的心跳都超时了，才会把主库判断为客观下线，然后，哨兵开始执行切换操作。哨兵切换完成后，客户端会和新主库进行通信，发送请求操作。在切换过程中，既然客户端仍然和原主库通信，这就表明，**原主库并没有真的发生故障**（例如主库进程挂掉）。
>
> 小结： 主库假故障

#### 33.2 脑裂为什么会发生数据丢失

> 主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行 slave of 命令，和新主库重新进行全量同步。而在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的 RDB 文件，这样一来，原主库在主从切换期间保存的新写数据就丢失了。

#### 33.3 如何应对脑裂问题

> 通过设置参数  min slaves-to-write 和 min-slaves-max-lag
>
> min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；
>
> min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送ACK 消息的最大延迟（以秒为单位）。
>
> 即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自
>
> 然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves
>
> max-lag 的组合要求就无法得到满足，原主库就会被限制接收客户端请求，客户端也就不
>
> 能在原主库中写入新数据了。

### 三十四、 23-33课后问题解答

######  问题：Redis 的只读缓存和使用直写策略的读写缓存，都会把数据同步写到后端数据库中，你觉得它们有什么区别吗？(23)

> 主要的区别在于，当有缓存数据被修改时，在只读缓存中，业务应用会直接修改数据库，并把缓存中的数据标记为无效；而在读写缓存中，业务应用需要同时修改缓存和数据库。

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210420095210917.png" alt="image-20210420095210917" style="zoom:50%;float:left" />

###### 问题：在讲到缓存雪崩时，我提到，可以采用服务熔断、服务降级、请求限流三种方法来应对。请你思考下，这三个方法可以用来应对缓存穿透问题吗？(26)

> 缓存穿透这个问题的本质是查询了，数据库、redis 中没有的数据。而上述三种方法就是解决redis无法起到缓存作用，可以用于解决缓存雪崩、缓存缓存击穿。
>
> 缓存穿透：可以利用布隆过滤器来进行快速判断

###### 问题：使用了 LFU 策略后，缓存还会被污染吗？(27)

> 还是可能会污染，如果某一个key在短时间高频访问，但是设置计数衰减值很小，导致改key还是长时间驻留，导致缓存污染

###### 问题：在执行事务时，如果 Redis 实例发生故障，而 Redis 使用的是 RDB 机制，那么，事务的原子性还能得到保证吗？

> 因为事务执行的时候，不会进行生成RDB文件
>
> 分为 3种情况：
>
> a.事务执行到一半时，事务失败，因为RDB中没有记录，所有不影响
>
> b.事务执行完成，并且生成了RDB 文件，不影响
>
> c.事务执行完成，但是未生成RDB文件，影响

###### 问题：：假设我们将 min-slaves-to-write 设置为 1，min-slaves-max-lag 设置为 15s，哨兵的 down-after-milliseconds设置为 10s，哨兵主从切换需要 5s，而主库因为某些原因卡住了 12s。此时，还会发生脑裂吗？主从切换完成后，数据会丢失吗？

> 会发生脑裂； 卡住12s ,判断主管下线，然后主重切换 15此时<= min-slaves-max-lag,但是在切换的过程中，故障的主库又恢复了，所以会发生脑裂



### 三十五、Codis集群

**codis架构图：**

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210420195309343.png" alt="image-20210420195309343" style="zoom:50%;float:left" />

> codis server 负责数据的读写
>
> codis proxy 接收客户端请求并转发给 codes server
>
> Zookeeper 集群 保存集群元数据
>
> codis dashboard 和 codis fe 集群管理工具

##### 1.数据是如何在多个实例上分布的：

> Codis 集群一共有 1024 个 Slot。数据可以分部在不同的槽上

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210420200042530.png" alt="image-20210420200042530" style="zoom:50%;float:left" />

######  Codis 与 Redis Cluster 数据分布实现区别

> 1、Codis ：Slot 和 codis server 的映射关系称为数据路由表（简称路由表），codis将信息存储在zookeepe当中；当路由表被修改后，dashbaord 就会把修改后的路由表发送给 codis proxy，就可以直接使用
>
> 2、Redis Cluster：数据路由表是通过每个实例相互间的通信传递的，最后会在每个实例上保存一份。所以当修改之后，会在不同的节点间相互通信，可能会造成网络拥塞

##### 2.集群扩容和数据迁移如何进行?

> Codis 集群扩容包括了两方面：增加 codis server 和增加 codis proxy

###### a.增加 codis server  

> 基本流程： 
>
> 1、从源server中选取一个数据，发送给目标server
>
> 2、目标server接收数据后，发送a c k ，源server会删除已发送数据
>
> 重复 1-2 直到数据都被迁移

###### server迁移  有两种方式：同步迁移和异步迁移

**同步迁移：**在迁移的过程中会阻塞，无法处理用户请求

**异步迁移：**源server发送数据后，可以接受请求，目的server接收数据后，会先序列化到本地，然后发送a c k消息给源主机，此过程中的源数据，为被处理为只读；对于大的bigkey采用了拆分之指令的方式，化整为零的方式进行发送（并且为了防止发送过程中出错，并设置了ke y的过期时间，保证了原子性）可以通过设置 **SLOTSMGRTTAGSLOT-ASYNC 的参数numkeys 设置每次迁移的 key 数量**。

###### b.增加 codis proxy

> 直接启动 proxy，再通过 codis dashboard 把 proxy 加入集群就行。

####   切片集群方案选择建议

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210420223355834.png" alt="image-20210420223355834" style="zoom:50%;float:left" />

> 从稳定性和成熟度来讲，Codis 应用得比较早，在业界已经有了成熟的生产部署
>
> 从客户端兼容性来讲， Redis Cluster 的话，就需要开发新功能
>
> Redis 新命令和新特性来看，，Codis server 是基于开源的 Redis 3.2.8 开发的，所以，Codis 并不支持 Redis 后续的开源版本中的新增命令和数据类型

### 三十六、Redis支撑秒杀场景

###### 秒杀的特点

1、瞬间并发访问量特别高

2、读多写少，读也就是简单读查询操作

#### 36.1秒杀的三个阶段

##### 1、秒杀前

> 用户会不断刷新商品页面，可以用cdn或者静态元素缓存起来

##### 2、秒杀活动开始

这个也分为3个过程：库存检查、库存减扣、订单处理。压力最大的就是库存检查

**Redis处理：**库存检查、库存减扣

**数据库处理：**订单处理，因为这一系列涉及其他表和事务操作。

##### 3、秒杀活动结束之后

#### 36.2 **Redis** 的哪些方法可以支撑秒杀场景？

1、**支持高并发**

2、**保证库存查验和库存扣减原子性执行**。使用redis的原子操作或者是分布式锁完成。

##### 小结

> 我们可以使用切片集群中的不同实例来分别保存分布式锁和商品库存信息

### 三十七、数据分布优化：如何应对数据倾斜

**数据倾斜**

> 1、数据量倾斜：实中的数据分布不均，某个实例的数据量特别大
>
> 2、数据访问倾斜：虽然每个集群的数据量相差不大，但是不同节点的访问差异很大

##### 37.1 数据量倾斜的成因和应对办法

有下面3个方面会导致 **数据量倾斜**

###### a . bigkey导致

> 避免方法，需要拆分处理

###### b.**Slot** **分配不均衡导致倾斜**

> 运维人员没有均匀的分配Sloat，就会有大量的数据被分配到一个Sloat中。

###### c.使用Hash Tag进行数据切片

> 当在key 中使用{}时，例如：user:profile:{3231}，只会在针对括号部分CRC16. 通常 tag的作用是用于事务操作和范围查询。



##### 37.2 **数据访问倾斜的成因和应对方法**

###### 热点数据造成访问倾斜

> 解决方法：采用多点 solat数据备份的方式处理，只适合只读的方式，如果是读写的数据，就会有一致性的问题。

##### 小结：

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210422200842660.png" alt="image-20210422200842660" style="zoom:40%;float:left" />

### 三十八、集群间的网络通信

集群间的网络通信受两个方面的影响

**消息内容：**实例信息 + solat信息 + 其他实例信息

**传递频率：**在相互通信过程中如果发现改实例子，最近一次接收pong的时间大于， cluster-node

timeout 的一半了（cluster-node-timeout/2），就会立即给实例发送pone信息。

**所以我们可以适当调整cluster-node-timeout，来控制实例之间的通信**

### 四十、Redis 6.0新特性；多线程、客户端缓存与安全

##### 40.1 多线程

> Reids6.0 对于网络处理部分使用 多线程来处理网络

**阶段一：服务端和客户端建立 Socket 连接，并分配处理线程**

**阶段二：IO 线程读取并解析请求（多线程）**

**阶段三：主线程执行请求操作（单线程）**

**阶段四：IO 线程回写 Socket 和主线程清空全局队列(多线程)**



##### 40.2 服务端协助客户端缓存

> Redis 6.0 新增了一个重要的特性，就是实现了服务端协助的客户端缓存功能，也称为跟踪（Tracking）功能

**a.普通模式：**订阅了才发送

**b.广播模式：**所有专关注的发送

##### 40.3 **启用** **RESP 3** **协议**

> RESP2 : 是通过数组的方式通信
>
> RESP3: 支持多种数据类型的区分编码。

###### 小结

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210422210522044.png" alt="image-20210422210522044" style="zoom:50%;float:left" />

#### **NVM的特点**

> 能持久化保存数据；
>
> 读写速度和 DRAM 接近；
>
> 容量大。

**Redis在涉及持久化操作的问题**

> RDB在fork主线程操作的时候，会阻塞主线程
>
> AOF文件在记录日志是，性能和可靠性之间的平衡
>
> 使用RDB或AOF操作时，恢复销量受RDB和AOF的大小限制

### 四十一、35-40课后问题

###### 1、red is 与 Memcached 的差别

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210426080042954.png" alt="image-20210426080042954" style="zoom: 50%;" />



### 最后小结

<img src="https://gitee.com/liuzihao169/pic/raw/master/image/image-20210426081649069.png" alt="image-20210426081649069" style="zoom:50%;" />







